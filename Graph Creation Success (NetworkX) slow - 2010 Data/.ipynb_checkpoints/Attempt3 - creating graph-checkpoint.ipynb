{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 481 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Creating the mapping\n",
    "## 1. transactionHash- Integer ID mapping\n",
    "\n",
    "list_tx_hashes = []\n",
    "path = r\"C:\\Users\\Ashish Lakhmani\\Downloads\\edges2010\"\n",
    "for root, dir, files in os.walk(path):\n",
    "    for f in files:\n",
    "        with open(os.path.join(root,f), encoding = \"utf-8\") as f:\n",
    "            for line in f:\n",
    "                ## Split the row\n",
    "                cells = line.split(\"\\t\")\n",
    "\n",
    "                ## Add transaciton to Set\n",
    "                transaction_hash = cells[1]\n",
    "                list_tx_hashes.append(transaction_hash)\n",
    "                \n",
    "                \n",
    "list_tx_hashes = list(set(list_tx_hashes))\n",
    "txn_mapping = dict(zip(list_tx_hashes, range(len(list_tx_hashes))))\n",
    "del list_tx_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Creating the mapping\n",
    "##  Address- Integer ID mapping\n",
    "\n",
    "list_addresses = []\n",
    "path = r\"C:\\Users\\japje\\BDAProj\\edges2010\"\n",
    "for root, dir, files in os.walk(path):\n",
    "    for f in files:\n",
    "        if(\"outputs\" in f):\n",
    "            with open(os.path.join(root,f), encoding = \"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    ## Split the row\n",
    "                    cells = line.split(\"\\t\")\n",
    "\n",
    "                    ## Add address to Set\n",
    "                    addresses = cells[2:][::2]\n",
    "                    list_addresses = list_addresses + addresses\n",
    "                \n",
    "                \n",
    "list_addresses = list(set(list_addresses))\n",
    "addr_mapping = dict(zip(list_addresses, range(len(list_addresses))))\n",
    "del list_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Serialize Txn and Addr mappings\n",
    "\n",
    "# import pickle\n",
    "# path_txn_mapping2010 = r\"C:\\Users\\japje\\BDAProj\\Working2010\\txnHashtoID_mapping_2010.pickle\"\n",
    "# path_addr_mapping2010 = r\"C:\\Users\\japje\\BDAProj\\Working2010\\AddrToID_mapping_2010.pickle\"\n",
    "# with open(path_txn_mapping2010, \"wb\") as f:\n",
    "#     pickle.dump(txn_mapping, f)\n",
    "\n",
    "# with open(path_addr_mapping2010, \"wb\") as f1:\n",
    "#     pickle.dump(addr_mapping, f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing parse logic\n",
    "\n",
    "# sample_op_row = \"1279128036\t912c869c1ff6acaa9ca9d38ee66933c167ac980ee1c3e20086e3e6dd6a8896ef\t18gBZnsuSrhYLjvPUgwvDUJmksfREUGBTT\t1000000\t1M5o4Es83Ls4UJ3md94FbLbebLhWzF8eQc\t3079000000\"\n",
    "\n",
    "# cells = sample_op_row.split(\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Generation of output mappings\n",
    "## 1. txnID -> output_index -> OutputID\n",
    "## 2. OutputID -> addressID -> amount\n",
    "\n",
    "list_addresses = []\n",
    "path = r\"C:\\Users\\japje\\BDAProj\\edges2010\"\n",
    "mapping_tx_to_op = {}\n",
    "mapping_op = {}\n",
    "global_index = 0\n",
    "for root, dir, files in os.walk(path):\n",
    "    for f in files:\n",
    "        if(\"outputs\" in f):\n",
    "            with open(os.path.join(root,f), encoding = \"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    ## Split the row\n",
    "                    cells = line.rstrip().split(\"\\t\")\n",
    "                    # print(cells)\n",
    "                    list_tx_index = list(range(0, len(cells[2:])//2))\n",
    "                    list_addr_id = list(range(global_index+1, global_index+1+len(cells[2:])//2))\n",
    "                    list_tx_rep = [txn_mapping[cells[1]]] * (len(cells[2:])//2)\n",
    "\n",
    "                    list_addresses = [addr_mapping[x] for x in cells[2:][::2]]\n",
    "                    list_amounts = cells[3:][::2]\n",
    "\n",
    "                    mapping_delta1 = {x: {y: z} for x, y, z in zip(list_tx_rep, list_tx_index, list_addr_id)}\n",
    "\n",
    "                    mapping_delta2 = {x: {y: z} for x, y, z in zip(list_addr_id, list_addresses, list_amounts)}\n",
    "\n",
    "                    mapping_tx_to_op.update(mapping_delta1)\n",
    "                    mapping_op.update(mapping_delta2)\n",
    "                    global_index = global_index+1\n",
    "                global_index = global_index+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\japje\\\\BDAProj\\\\Working2010\\\\txnID_index_to_outputID_mapping_2010.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b80a3e9db962>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpath_opID_to_addrAmt_mapping2010\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"C:\\Users\\japje\\BDAProj\\Working2010\\opID_to_addrAmt_mapping2010.pickle\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_txn_to_op_mapping2010\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m    \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapping_tx_to_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\japje\\\\BDAProj\\\\Working2010\\\\txnID_index_to_outputID_mapping_2010.pickle'"
     ]
    }
   ],
   "source": [
    " ## Serialize output mappings\n",
    "\n",
    "import pickle\n",
    "path_txn_to_op_mapping2010 = r\"C:\\Users\\japje\\BDAProj\\Working2010\\txnID_index_to_outputID_mapping_2010.pickle\"\n",
    "path_opID_to_addrAmt_mapping2010 = r\"C:\\Users\\japje\\BDAProj\\Working2010\\opID_to_addrAmt_mapping2010.pickle\"\n",
    "\n",
    "with open(path_txn_to_op_mapping2010, \"wb\") as f:\n",
    "    pickle.dump(mapping_tx_to_op, f)\n",
    "\n",
    "with open(path_opID_to_addrAmt_mapping2010, \"wb\") as f1:\n",
    "    pickle.dump(mapping_op, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining 2 node classes\n",
    "\n",
    "# class Transaction:\n",
    "#     def __init__(self, id):\n",
    "#         self.id = id\n",
    "\n",
    "# class Output:\n",
    "#     def __init__(self, addr_id, amount):\n",
    "#         self.addr_id = addr_id\n",
    "#         self.amount = amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading inputs to create input mapping {transactionID --> [output indexes]}\n",
    "## Adding edges\n",
    "\n",
    "path = r\"C:\\Users\\japje\\BDAProj\\edges2010\"\n",
    "# mapping_tx_to_op = {}\n",
    "mapping_ip = {}\n",
    "for root, dir, files in os.walk(path):\n",
    "    for f in files:\n",
    "        if(\"inputs\" in f):\n",
    "            # print(f)\n",
    "            with open(os.path.join(root,f), encoding = \"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    cells = line.rstrip().split(\"\\t\")\n",
    "                    txn_id = txn_mapping[cells[1]]\n",
    "                    \n",
    "                    inputs = cells[2:]\n",
    "                    input_index = []\n",
    "                    for i in range(0, len(inputs)):\n",
    "                        # print(str(inputs[i]) + \"----\"+str(inputs[i+1]))\n",
    "                        try:\n",
    "                            print(str(txn_mapping[inputs[i]]) + \"----\" + str(inputs[i+1]))\n",
    "                            input_index.append(mapping_tx_to_op[int(txn_mapping[inputs[i]])][int(inputs[i+1])])\n",
    "                        except:\n",
    "                            pass\n",
    "                        i = i+2\n",
    "                    mapping_ip[txn_id] = input_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Serialize input mapping\n",
    "import pickle\n",
    "path_ip_mapping2010 = r\"C:\\Users\\japje\\BDAProj\\Working2010\\inp_mapping_2010.pickle\"\n",
    "\n",
    "\n",
    "with open(path_ip_mapping2010, \"wb\") as f:\n",
    "    pickle.dump(mapping_ip, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. generate directed graph (NetworkX library) - Insert transactions (prefix \"t-\") and outputs from the output file\n",
    "\n",
    "## Initialize\n",
    "G = nx.DiGraph()\n",
    "\n",
    "## Adding the transactions and outputs from output mappings\n",
    "for k in mapping_tx_to_op:\n",
    "    G.add_node(\"t_\"+ str(k))\n",
    "    connected_op = list(mapping_tx_to_op[k].values())\n",
    "    # print(connected_op)\n",
    "    G.add_nodes_from(connected_op)\n",
    "    G.add_edges_from([(\"t_\"+ str(k), y) for y in connected_op])\n",
    "    \n",
    "## Adding additional edges from input mapping\n",
    "for k in mapping_ip:\n",
    "    inputs = mapping_ip[k]\n",
    "    # print([(\"t_\"+ str(k), y) for y in inputs])\n",
    "    G.add_edges_from([(\"t_\"+ str(k), y) for y in inputs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Serialize Graph\n",
    "\n",
    "nx.write_gpickle(G, r\"C:\\Users\\japje\\BDAProj\\Working2010\\DiGraph.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# G[Transaction(12)].edges\n",
    "\n",
    "# for n in G:\n",
    "#     print(n.id)\n",
    "\n",
    "G[t1][o3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ##testing networkx\n",
    "\n",
    "# ## 1. generate graph\n",
    "\n",
    "# t1 = Transaction(12)\n",
    "# t2 = Transaction(123)\n",
    "# t3 = Transaction(43)\n",
    "\n",
    "# o1 = Output(12, 3400000)\n",
    "# o2 = Output(15, 34000000)\n",
    "# o3 = Output(126, 34000004)\n",
    "\n",
    "# G = nx.DiGraph()\n",
    "# G.add_node(t1)\n",
    "# G.add_node(t2)\n",
    "# G.add_node(t3)\n",
    "\n",
    "# G.add_node(o1)\n",
    "# G.add_node(o2)\n",
    "# G.add_node(o3)\n",
    "\n",
    "# G.add_edge(t1, o2)\n",
    "# G.add_edge(t2, o1)\n",
    "# G.add_edge(t1, o3)\n",
    "# G.add_edge(t3, o1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 76,\n",
       " 79,\n",
       " 80,\n",
       " 84,\n",
       " 92,\n",
       " 96,\n",
       " 101,\n",
       " 105,\n",
       " 106,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 131,\n",
       " 136,\n",
       " 162,\n",
       " 175,\n",
       " 199,\n",
       " 205,\n",
       " 279,\n",
       " 287,\n",
       " 314,\n",
       " 363,\n",
       " 384,\n",
       " 387,\n",
       " 451,\n",
       " 490}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([len(x) for x in mapping_ip.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_tx_to_op[96434][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
